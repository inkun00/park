import os
import io
import json
import base64
import openai
import streamlit as st
import streamlit.components.v1 as components

# -------------------
# OpenAI API Key Setup
# -------------------
api_key_env = os.getenv("OPENAI_API_KEY", "")
api_key_input = ""
if not api_key_env:
    api_key_input = st.text_input("ğŸ”‘ OpenAI API Key ì…ë ¥ (sk-...)", type="password")
openai.api_key = api_key_input or api_key_env

# -------------------
# Helper Functions
# -------------------

def transcribe_audio(audio_bytes: bytes) -> str:
    """Whisperâ€‘1ë¡œ ìŒì„± â†’ í…ìŠ¤íŠ¸."""
    audio_file = io.BytesIO(audio_bytes)
    audio_file.name = "audio.wav"  # íŒŒì¼ëª… í•„ìš”
    try:
        result = openai.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            response_format="text",
            language="ko"
        )
        return result  # response_format=text ì´ë©´ str ë°˜í™˜
    except openai.AuthenticationError:
        st.error("âŒ OpenAI API Keyê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.stop()


def chat_with_gpt(prompt: str, history: list[dict]) -> str:
    """GPTâ€‘4oë¡œ ëŒ€í™” ì‘ë‹µ ìƒì„±."""
    messages = []
    for turn in history:
        messages.append({"role": "user", "content": turn["user"]})
        messages.append({"role": "assistant", "content": turn["bot"]})
    messages.append({"role": "user", "content": prompt})
    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.7,
            max_tokens=200,
        )
        return response.choices[0].message.content.strip()
    except openai.AuthenticationError:
        st.error("âŒ OpenAI API Keyê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.stop()


def speak(text: str) -> bytes:
    """gptâ€‘4o TTS (20ëŒ€ ë‚¨ì„± í†¤: alloy) â†’ MP3 bytes ë°˜í™˜."""
    try:
        speech_resp = openai.audio.speech.create(
            model="gpt-4o-audio-preview",  # ìµœì‹  TTS í”„ë¦¬ë·° ëª¨ë¸
            voice="alloy",                 # ìì—°ìŠ¤ëŸ¬ìš´ ì Šì€ ë‚¨ì„± ìŒìƒ‰
            input=text,
            format="mp3",
        )
        return bytes(speech_resp)  # BinaryContent -> bytes
    except openai.AuthenticationError:
        st.error("âŒ OpenAI API Keyê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.stop()

# -------------------
# Streamlit UI
# -------------------
st.set_page_config(page_title="Voice Chatbot: ë°•ì¢…ì² ", layout="centered")
st.title("ğŸ—£ï¸ 1987ë…„ ë°•ì¢…ì²  ìŒì„± ì±—ë´‡")

# ì¤‘ì‹¬ ì˜ìƒ (assets/park_jongchul.mp4 ìœ„ì¹˜ì— íŒŒì¼ ë°°ì¹˜)
st.video("assets/park_jongchul.mp4", format="video/mp4")

# Session state for conversation
if "history" not in st.session_state:
    st.session_state.history = []

# Audio input (Streamlit â‰¥1.25)
st.subheader("ğŸ¤ ë§ˆì´í¬ ë…¹ìŒ")
audio_data = st.audio_input("ë²„íŠ¼ì„ ëˆŒëŸ¬ ì§ˆë¬¸ì„ ë…¹ìŒí•˜ì„¸ìš”")

if audio_data:
    # 1. STT
    user_text = transcribe_audio(audio_data.getbuffer())
    st.markdown(f"**ğŸ™‹â€â™‚ï¸ ì‚¬ìš©ì:** {user_text}")

    # 2. ChatGPTâ€‘4o ì‘ë‹µ
    bot_text = chat_with_gpt(user_text, st.session_state.history)
    st.markdown(f"**ğŸ¤– ë°•ì¢…ì² :** {bot_text}")

    # 3. TTS (ì Šì€ ë‚¨ì„± ìŒì„±)
    mp3_bytes = speak(bot_text)
    st.audio(mp3_bytes, format="audio/mp3")
    # ìë™ ì¬ìƒ
    b64 = base64.b64encode(mp3_bytes).decode()
    components.html(f'<audio autoplay src="data:audio/mp3;base64,{b64}"></audio>', height=0)

    # 4. Save to history
    st.session_state.history.append({"user": user_text, "bot": bot_text})

# Conversation log & copy
if st.session_state.history:
    convo = "\n".join([
        f"ì‚¬ìš©ì: {h['user']}\në°•ì¢…ì² : {h['bot']}" for h in st.session_state.history
    ])
    st.text_area("ğŸ“œ ëŒ€í™” ë‚´ì—­", value=convo, height=250)
    if st.button("ğŸ“‹ ëŒ€í™” ë³µì‚¬"):
        escaped = json.dumps(convo)
        components.html(
            f"<script>navigator.clipboard.writeText({escaped});</script>",
            height=0,
        )
        st.success("ëŒ€í™” ë‚´ìš©ì´ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
